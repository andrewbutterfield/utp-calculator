\section{Introduction}\label{sec:Intro}

\subsection{Motivation}

The developments of a Unifying Theory of Programming (UTP)
can involve a number of false starts,
as alphabet variables are chosen
and semantics and healthiness conditions are defined.
Typically, some calculations done just to check that everything
work reveal problems with the theory.
So an iteration occurs by revising the basic definitions,
and attempting the calculations again.

We have recently started to explore using UTP
to describe shared-variable concurrency,
by adapting the workof the  UTP semantics for Unifying Theories
of Parallel Programming (UTPP) \cite{DBLP:conf/icfem/WoodcockH02}.
We have reworked it to use a system for generating unique labels,
in order to give a slight improvement to the compositionality
of the semantics. This we call a Unifying Theory of Concurrent Programming
(UTCP) and details of this are,
at the time of writing,
accepted for publication\cite{conf/tase/BMN16}.

We give a very brief overview here of this theory.
The language assumes atomic actions ($A$) that modify a generic state,
and four composition operators: sequential ($\lseq$), parallel ($\parallel$),
non-deterministic choice ($\pcond$) and non-deterministic iterations ($\piter{}$)
\[
   P ::= A \mid P \pseq P \mid P \parallel P \mid P \pcond P \mid \piter P
\]
Note that this is essentially the same as the baseline ``Command'' language
in the Views paper\cite{conf/popl/Dinsdale-YoungBGPY13}.
So our UTCP theory is based on a non-homogeneous relation
with alphabet $s$, $s'$, $ls$, $ls'$, $g$, $in$, and $out$.
Observations $s$ and $ls$ (and dashed counterparts)
represent the shared state and the gloval label-set used for control flow.
Observations $g$, $in$ and $out$ are static parameters that do not change
at run time.


The theory with its somewhat unusual arrangement of observation variables
did \emph{not} emerge as an immediate and obvious solution,
but as a result of many trial calculations.
These trial calculations exposed two problems:
The first problem was relatively minor
---a lot of the semantics talks about the presence of various
labels in the global label-set, or alternatively, their  absence,
and of modifications to that set.
This resulted in very wide expressions,
so some shorthand notations were introduced.

The second problem was more serious.
It often took long painstaking calculations to discover problems
with a proposed version of the theory,
typically when trying to calculate outcomes associated with
$A \pseq B$ and then  $A \parallel B$
(400 lines of \LaTeX\,7 full pages of output)
With choice and iteration to be covered,
it was becoming very clear that a better way was required
for checking semantic outcomes.

If we consider the reasoning processes used in the development
and deployment of a theory, we can see a spectrum ranging from informal,
through to fully mechanised: hand calculation; simulation; proof assistant;
and automated theorem provers.
The level of detail, complexity, and rigour rises as we proceed along the spectrum.
The calculator described here is designed
to assist with the exploratory hand-calculation phase early on,
by making it easier to calculate, and to manually check the outcomes.
It is not intended to provide the soundness guarantees that are quite rightly
expected from the tools further along the spectrum.


\subsection{Structure of this paper}

In Sect.\ref{sec:Related} we discuss related work
to justify our decision to develop the calculator.
The key design decisions and tool architecture is then described
in Sect. \ref{sec:Design}.
Three key components of the system are the discussed:
Dictionaries (Sect.\ref{sec:Dictionaries});
Expressions (Sect.\ref{sec:Expressions}); and
Predicates (Sect.\ref{sec:Predicates}).
In Sect.\ref{sec:Laws} we describe how to encode laws
and then conclude in (Sect.\ref{sec:Conc}.
